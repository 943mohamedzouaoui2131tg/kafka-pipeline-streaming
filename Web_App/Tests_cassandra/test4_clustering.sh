#!/bin/bash

echo "=========================================="
echo "TEST DE SCALABILITÃ‰ HORIZONTALE"
echo "=========================================="

# Fonction pour extraire les valeurs JSON avec Python
parse_json() {
    python3 -c "import json, sys; data=json.load(sys.stdin); print($1)" 2>/dev/null || echo "0"
}

# Fonction pour tester les performances
test_performance() {
    local num_nodes=$1
    local phase=$2
    
    echo ""
    echo "â–¶ Phase $phase : Test avec $num_nodes nÅ“uds"
    echo "----------------------------------------"
    
    # Attendre que le cluster soit stable
    echo "Attente de stabilisation du cluster..."
    sleep 30
    
    # VÃ©rifier le statut du cluster
    echo "Statut du cluster :"
    docker exec cassandra1 nodetool status
    
    # Test Write
    echo ""
    echo "Test d'Ã©criture (5000 ops)..."
    curl -s -X POST http://localhost:5000/cassandra/test/scalability \
      -H "Content-Type: application/json" \
      -d '{"test_type": "write", "num_operations": 5000}' \
      -o "results_write_${num_nodes}nodes.json"
    
    if [ $? -eq 0 ]; then
        echo "RÃ©sultats Ã©criture:"
        cat "results_write_${num_nodes}nodes.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    write = data.get('results', {}).get('write_test', {})
    print(f\"  - Operations: {write.get('total_operations', 'N/A')} ops\")
    print(f\"  - Throughput: {write.get('throughput_ops_per_sec', 'N/A')} ops/sec\")
    print(f\"  - Latence moyenne: {write.get('avg_latency_ms', 'N/A')} ms\")
    print(f\"  - Latence P95: {write.get('p95_latency_ms', 'N/A')} ms\")
    print(f\"  - Latence P99: {write.get('p99_latency_ms', 'N/A')} ms\")
except Exception as e:
    print(f'Erreur parsing: {e}')
"
    else
        echo "âŒ Erreur lors du test d'Ã©criture"
    fi
    
    # Test Read
    echo ""
    echo "Test de lecture (500 ops)..."
    curl -s -X POST http://localhost:5000/cassandra/test/scalability \
      -H "Content-Type: application/json" \
      -d '{"test_type": "read", "num_operations": 500}' \
      -o "results_read_${num_nodes}nodes.json"
    
    if [ $? -eq 0 ]; then
        echo "RÃ©sultats lecture:"
        cat "results_read_${num_nodes}nodes.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    read = data.get('results', {}).get('read_test', {})
    print(f\"  - Operations: {read.get('total_operations', 'N/A')} ops\")
    print(f\"  - Throughput: {read.get('throughput_ops_per_sec', 'N/A')} ops/sec\")
    print(f\"  - Latence moyenne: {read.get('avg_latency_ms', 'N/A')} ms\")
    print(f\"  - Latence P95: {read.get('p95_latency_ms', 'N/A')} ms\")
    print(f\"  - Latence P99: {read.get('p99_latency_ms', 'N/A')} ms\")
except Exception as e:
    print(f'Erreur parsing: {e}')
"
    else
        echo "âŒ Erreur lors du test de lecture"
    fi
    
    # Test Mixte
    echo ""
    echo "Test mixte (3000 ops)..."
    curl -s -X POST http://localhost:5000/cassandra/test/scalability \
      -H "Content-Type: application/json" \
      -d '{"test_type": "mixed", "num_operations": 3000}' \
      -o "results_mixed_${num_nodes}nodes.json"
    
    if [ $? -eq 0 ]; then
        echo "RÃ©sultats mixte:"
        cat "results_mixed_${num_nodes}nodes.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    results = data.get('results', {})
    cluster = results.get('cluster_info', {})
    cpu_mem = results.get('cpu_memory', [])
    
    print(f\"  - Nombre de nÅ“uds: {cluster.get('num_nodes', 'N/A')}\")
    print(f\"  - Replication factor: {cluster.get('replication_factor', 'N/A')}\")
    
    if cpu_mem:
        print(\"  - CPU/MÃ©moire par nÅ“ud:\")
        for node in cpu_mem:
            print(f\"    * {node.get('node', 'N/A')}: CPU {node.get('cpu_percent', 'N/A')}%, MEM {node.get('memory_percent', 'N/A')}%\")
except Exception as e:
    print(f'Erreur parsing: {e}')
"
    else
        echo "âŒ Erreur lors du test mixte"
    fi
    
    # MÃ©triques cluster
    echo ""
    echo "Statistiques du cluster :"
    docker exec cassandra1 nodetool tablestats projet_bd_rf3.trips_by_borough_time > "stats_${num_nodes}nodes.txt" 2>&1
    docker exec cassandra1 nodetool tpstats > "tpstats_${num_nodes}nodes.txt" 2>&1
    
    echo "âœ“ Phase $phase terminÃ©e"
    echo ""
}

# Baseline : 3 nÅ“uds
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "BASELINE : 3 NÅ’UDS"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
test_performance 3 "1-BASELINE"

# Ajouter le 4Ã¨me nÅ“ud
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "AJOUT DU 4ÃˆME NÅ’UD"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
docker-compose up -d cassandra4
echo "Attente du dÃ©marrage du nÅ“ud 4 (120 secondes)..."
sleep 120

echo "VÃ©rification du statut..."
docker exec cassandra1 nodetool status

echo "Lancement du repair pour redistribuer les donnÃ©es..."
docker exec cassandra1 nodetool repair projet_bd_rf3

test_performance 4 "2-AFTER-NODE4"

# Ajouter le 5Ã¨me nÅ“ud
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "AJOUT DU 5ÃˆME NÅ’UD"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
docker-compose up -d cassandra5
echo "Attente du dÃ©marrage du nÅ“ud 5 (120 secondes)..."
sleep 120

echo "VÃ©rification du statut..."
docker exec cassandra1 nodetool status

echo "Lancement du repair..."
docker exec cassandra1 nodetool repair projet_bd_rf3

test_performance 5 "3-AFTER-NODE5"

# Ajouter le 6Ã¨me nÅ“ud
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "AJOUT DU 6ÃˆME NÅ’UD"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
docker-compose up -d cassandra6
echo "Attente du dÃ©marrage du nÅ“ud 6 (120 secondes)..."
sleep 120

echo "VÃ©rification du statut..."
docker exec cassandra1 nodetool status

echo "Lancement du repair..."
docker exec cassandra1 nodetool repair projet_bd_rf3

test_performance 6 "4-AFTER-NODE6"

# Analyse comparative
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ANALYSE COMPARATIVE"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

echo ""
echo "CrÃ©ation du rapport comparatif..."

python3 << 'EOF'
import json
import glob

print("\nğŸ“Š RAPPORT DE SCALABILITÃ‰\n")
print("="*60)

# Collecte des rÃ©sultats
results_summary = {}

for filepath in sorted(glob.glob("results_write_*nodes.json")):
    try:
        nodes = filepath.split("_")[2].replace("nodes.json", "")
        with open(filepath, 'r') as f:
            data = json.load(f)
            write_test = data.get('results', {}).get('write_test', {})
            
            if nodes not in results_summary:
                results_summary[nodes] = {}
            
            results_summary[nodes]['write'] = {
                'throughput': write_test.get('throughput_ops_per_sec', 0),
                'latency': write_test.get('avg_latency_ms', 0),
                'p95': write_test.get('p95_latency_ms', 0)
            }
    except Exception as e:
        print(f"Erreur lecture {filepath}: {e}")

for filepath in sorted(glob.glob("results_read_*nodes.json")):
    try:
        nodes = filepath.split("_")[2].replace("nodes.json", "")
        with open(filepath, 'r') as f:
            data = json.load(f)
            read_test = data.get('results', {}).get('read_test', {})
            
            if nodes not in results_summary:
                results_summary[nodes] = {}
            
            results_summary[nodes]['read'] = {
                'throughput': read_test.get('throughput_ops_per_sec', 0),
                'latency': read_test.get('avg_latency_ms', 0),
                'p95': read_test.get('p95_latency_ms', 0)
            }
    except Exception as e:
        print(f"Erreur lecture {filepath}: {e}")

# Affichage
print("\nğŸ“ THROUGHPUT D'Ã‰CRITURE (ops/sec)")
print("-" * 60)
for nodes in sorted(results_summary.keys(), key=int):
    throughput = results_summary[nodes].get('write', {}).get('throughput', 0)
    print(f"  {nodes} nÅ“uds: {throughput:.2f} ops/sec")

print("\nğŸ“ LATENCE MOYENNE D'Ã‰CRITURE (ms)")
print("-" * 60)
for nodes in sorted(results_summary.keys(), key=int):
    latency = results_summary[nodes].get('write', {}).get('latency', 0)
    print(f"  {nodes} nÅ“uds: {latency:.2f} ms")

print("\nğŸ“ LATENCE P95 D'Ã‰CRITURE (ms)")
print("-" * 60)
for nodes in sorted(results_summary.keys(), key=int):
    p95 = results_summary[nodes].get('write', {}).get('p95', 0)
    print(f"  {nodes} nÅ“uds: {p95:.2f} ms")

print("\nğŸ“ THROUGHPUT DE LECTURE (ops/sec)")
print("-" * 60)
for nodes in sorted(results_summary.keys(), key=int):
    throughput = results_summary[nodes].get('read', {}).get('throughput', 0)
    print(f"  {nodes} nÅ“uds: {throughput:.2f} ops/sec")

print("\nğŸ“ LATENCE MOYENNE DE LECTURE (ms)")
print("-" * 60)
for nodes in sorted(results_summary.keys(), key=int):
    latency = results_summary[nodes].get('read', {}).get('latency', 0)
    print(f"  {nodes} nÅ“uds: {latency:.2f} ms")

# Calcul amÃ©lioration
if '3' in results_summary and '6' in results_summary:
    print("\nğŸ“ˆ AMÃ‰LIORATION 3â†’6 NÅ’UDS")
    print("-" * 60)
    
    write_improvement = (
        (results_summary['6']['write']['throughput'] - results_summary['3']['write']['throughput']) 
        / results_summary['3']['write']['throughput'] * 100
    ) if results_summary['3']['write']['throughput'] > 0 else 0
    
    read_improvement = (
        (results_summary['6']['read']['throughput'] - results_summary['3']['read']['throughput']) 
        / results_summary['3']['read']['throughput'] * 100
    ) if results_summary['3']['read']['throughput'] > 0 else 0
    
    print(f"  Throughput Ã©criture: {write_improvement:+.1f}%")
    print(f"  Throughput lecture: {read_improvement:+.1f}%")

print("\n" + "="*60)
EOF

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "TEST DE SCALABILITÃ‰ TERMINÃ‰"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "RÃ©sultats sauvegardÃ©s dans:"
echo "  - results_*nodes.json (rÃ©sultats tests)"
echo "  - stats_*nodes.txt (statistiques tables)"
echo "  - tpstats_*nodes.txt (thread pool stats)"